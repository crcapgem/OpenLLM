{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c85226-64fe-4391-97c0-c33d41f00633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.11/site-packages (1.10.2)\n",
      "Collecting pydantic\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.11/site-packages (from pydantic) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic) (4.12.2)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.2\n",
      "    Uninstalling pydantic-1.10.2:\n",
      "      Successfully uninstalled pydantic-1.10.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-groq 0.1.10 requires langchain-core<0.3.0,>=0.2.39, but you have langchain-core 0.3.6 which is incompatible.\n",
      "langchain-experimental 0.0.65 requires langchain-community<0.3.0,>=0.2.16, but you have langchain-community 0.3.1 which is incompatible.\n",
      "langchain-experimental 0.0.65 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pydantic-2.9.2\n"
     ]
    }
   ],
   "source": [
    "#pip install pydantic==1.10.2\n",
    "!pip install --upgrade pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7223cf5f-eccc-4b89-b416-bdb0fdfa7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_aws4auth import AWS4Auth\n",
    "import boto3\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from langchain_aws import ChatBedrock\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0af1d58-bf92-46ba-8050-4ebeb210bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERIES = {\n",
    "    '1': 'Which transformer is needing an immediate attention?',\n",
    "    '2': 'For transformers 2217, 1235, 1685 and 2484 provide comparative details for transformer health based on Oil quality testing ( dielectric breakdown voltage, IFT, acidity, moisture content, furan analysis) , DGA ( duval, rogers ratio, key gas method), Power factor (IPF/IR), temperature monitoring (top oil temperature , hot spot temperature, cooling efficiency) , load/overload history ( loading prof, percentage overload), partial discharge , electrical testing ( FRA, WRM, Turns ratio, capacitance and dissipation factor) , TAIM, LEDT, dornenburgs method, bushing health (capacitance and power factor, DGA for bushings), THI (HI, risk of failure), LTC. Ensure you provide details on parameter, significance, calculation details, root cause analysis details, actions and measures that must be taken , advice to curb further damage for provided transformer details in a tabular format',\n",
    "    '3': 'what is the duval triangle 1,2,3 value for transformer 2484',\n",
    "    '4': 'How is my transformer fleet - 2217, 1235, 1685 and 2484 doing?'\n",
    "}\n",
    "INDEX_CONFIG ={'Hackathon_index': 'innovator_hack_index'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eeadc7-abbb-4815-b533-912413491d75",
   "metadata": {},
   "source": [
    "# Keyword Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "840f31c0-c5ed-449a-ae51-d3ff4b4c01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_aws import ChatBedrock\n",
    "import re\n",
    "\n",
    "def load_model():\n",
    "    # bedrock client\n",
    "    bedrock_runtime = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=\"us-east-1\",\n",
    "    )\n",
    "    # Update to use amazon.titan-text-premier-v1:0\n",
    "    model_id = \"amazon.titan-text-premier-v1:0\"\n",
    "    model_kwargs = {\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\":1\n",
    "    }\n",
    "    # Bedrock chat model\n",
    "    model = ChatBedrock(\n",
    "        client=bedrock_runtime,\n",
    "        model_id=model_id,\n",
    "        model_kwargs=model_kwargs,\n",
    "    ).with_retry()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe1a942a-b43d-48d9-a05e-2d80463c30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_keywords(content):\n",
    "    must_keywords = []\n",
    "    should_keywords = []\n",
    "\n",
    "    # Extract the Must Keywords line\n",
    "    must_line = re.search(r'Numerical Keywords: \\[(.*?)\\]', content)\n",
    "    if must_line:\n",
    "        must_keywords = [keyword.strip() for keyword in must_line.group(1).split(',')]\n",
    "\n",
    "    # Extract the Should Keywords line\n",
    "    should_line = re.search(r'Text Keywords: \\[(.*?)\\]', content)\n",
    "    if should_line:\n",
    "        should_keywords = [keyword.strip() for keyword in should_line.group(1).split(',')]\n",
    "\n",
    "    return must_keywords, should_keywords\n",
    "\n",
    "def extract_keywords(query):\n",
    "    prompt = f\"\"\"\n",
    "    Extract the keywords from the following query: \"{query}\"\n",
    "    Keywords should include specific identifiers like transformer numbers, names, or other entities relevant to the query.\n",
    "    Transformer should never be a keyword.\n",
    "    If the keyword is clearly a transformer ID and it doesn't start with 'TXID_', add this to its prefix\n",
    "    The output should have format of: Numerical Keywords: [...]; Text Keywords: [...]\n",
    "    \n",
    "    <example>\n",
    "    Input: provide comparative analysis of transformers - 2217, 1235, 1685 and 2484 based on their parameters?\n",
    "    Output: Numerical Keyword: [TXID_2217, TXID_1235, TXID_1685, TXID_2484]; Text Keyword: …\n",
    "    \n",
    "    Input: what is the duval triangle 1,2,3 value for transformer 2484\n",
    "    Output: Numerical Keyword: [TXID_2484]; Text Keyword: [duval triangle]\n",
    "    \"\"\"\n",
    "    \n",
    "    model = load_model()\n",
    "    response = model.invoke(prompt)\n",
    "    \n",
    "    content = response.content\n",
    "    print(content)\n",
    "    \n",
    "    return parse_keywords(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627bf95-47fb-4590-b80a-7c84462193fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b81a62d4-309e-48f4-a0f8-920999688068",
   "metadata": {},
   "source": [
    "# Searching Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63f92948-1044-4bc4-a486-adccd9e35284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search(opensearch_client, index_name, query, k=2):\n",
    "    must_keywords, should_keywords = extract_keywords(query)\n",
    "\n",
    "    msearch_body = []\n",
    "    if must_keywords:\n",
    "        for keyword in must_keywords:\n",
    "            msearch_body.append({'index': index_name})\n",
    "            \n",
    "            msearch_body.append({\n",
    "                'size': k, \n",
    "                'query': {\n",
    "                    'bool': {\n",
    "                        'must': [\n",
    "                            {\n",
    "                                'match_phrase': {\n",
    "                                    'content': keyword\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                        'should': [\n",
    "                            {\n",
    "                                'match': {\n",
    "                                    'content': should_keyword\n",
    "                                }\n",
    "                            } for should_keyword in should_keywords\n",
    "                        ],\n",
    "                        'minimum_should_match': 0 \n",
    "                    }\n",
    "                }\n",
    "            })\n",
    "\n",
    "    response = opensearch_client.msearch(body=msearch_body)\n",
    "\n",
    "    all_results = []\n",
    "    for res in response['responses']:\n",
    "        if 'hits' in res and 'hits' in res['hits']:\n",
    "            all_results.extend(res['hits']['hits'])  \n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "\n",
    "def vector_search(opensearch_client, index_name, embedding_model, query, k=2):\n",
    "    query_vector = embedding_model.embed_documents([query])[0]\n",
    "    response = opensearch_client.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            'size': k,\n",
    "            'query': {\n",
    "                'knn': {\n",
    "                    'embedding': {\n",
    "                        'vector': query_vector,\n",
    "                        'k': k\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return response['hits']['hits']\n",
    "\n",
    "def print_query_result(query, results, search_type):\n",
    "    search_results = \"\"\n",
    "    \n",
    "    if not results:\n",
    "        search_results += f\"# Query: {query} ({search_type} search)\"\n",
    "        search_results += \"--------------------------------\"\n",
    "        search_results += \"No results found.\"\n",
    "        search_results += \"--------------------------------\"\n",
    "        print(search_results)\n",
    "        return search_results\n",
    "\n",
    "    df = pd.concat([pd.DataFrame([result['_source'] if isinstance(result, dict) else result]) for result in results], ignore_index=True)\n",
    "    search_results += f\"# Query: {query} ({search_type} search)\"\n",
    "    search_results += \"--------------------------------\"\n",
    "    for i, result in enumerate(results):\n",
    "        # print(result)\n",
    "        metadata = result['_source'] if isinstance(result, dict) else result\n",
    "        search_results += f\"# {search_type} search result {i+1} (relevant document chunk):\"\n",
    "        search_results += f\"Source: {metadata['source']}\"\n",
    "        search_results += \"Content:\"\n",
    "        row_content = json.loads(metadata['content'])\n",
    "        for key, value in row_content.items():\n",
    "            search_results += f\"'{key}': {value}\"\n",
    "        search_results +=  \"--------------------------------\"\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb675ae0-834c-49e9-bfaf-54fe2bb1b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_queries(index_name, query, opensearch_client, embedding_model, search_type):\n",
    "\n",
    "    search_result = \"\"\n",
    "    if search_type == 'keyword':\n",
    "        print(f\"\\nTesting query {query} - Keyword Search:\")\n",
    "        results = keyword_search(opensearch_client, index_name, query)\n",
    "        search_result = print_query_result(query, results, \"Keyword\")\n",
    "    elif search_type == 'vector':\n",
    "        print(f\"\\nTesting query {query} - Vector Search:\")\n",
    "        results = vector_search(opensearch_client, index_name, embedding_model, query)\n",
    "        search_result = print_query_result(query, results, \"Vector\")\n",
    "    elif search_type == 'hybrid':\n",
    "        print(f\"\\nTesting query {query} - Hybrid Search:\")\n",
    "        results = keyword_search(opensearch_client, index_name, query) + vector_search(opensearch_client, index_name, embedding_model, query)\n",
    "        search_result = print_query_result(query, results, \"Hybrid\")\n",
    "    else:\n",
    "        print(f\"Unknown search type: {search_type}\")\n",
    "\n",
    "    formatted_output = format_output(query, [search_result])\n",
    "    # print(formatted_output)\n",
    "    return formatted_output\n",
    "\n",
    "def format_output(query, results):\n",
    "    formatted_results = []\n",
    "    for result in results:\n",
    "        formatted_results.append(f\"<documents>\\n{result}\\n</documents>\")\n",
    "    return f\"<query> # Query: {query} </query>\\n\" + \"\\n--------------------------------\\n\".join(formatted_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6aeba31f-1591-47b0-96a2-89341ec344cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenSearch client\n",
    "def init_opensearch_client(host, port, region, service):\n",
    "    credentials = boto3.Session().get_credentials()\n",
    "    awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
    "    return OpenSearch(\n",
    "        hosts=[{'host': host, 'port': port}],\n",
    "        http_auth=awsauth,\n",
    "        use_ssl=True,\n",
    "        verify_certs=True,\n",
    "        connection_class=RequestsHttpConnection,\n",
    "        timeout=3000\n",
    "    )\n",
    "\n",
    "\n",
    "opensearch_host = 'iellhhrn6kean028im78.us-east-1.aoss.amazonaws.com'\n",
    "opensearch_port = 443\n",
    "opensearch_region = 'us-east-1'\n",
    "opensearch_service = 'aoss'\n",
    "index_name = INDEX_CONFIG['Hackathon_index']\n",
    "dimension = 1024\n",
    "\n",
    "opensearch_client = init_opensearch_client(opensearch_host, opensearch_port, opensearch_region, opensearch_service)\n",
    "embedding_model = BedrockEmbeddings(client=boto3.client(\"bedrock-runtime\", region_name=opensearch_region), model_id=\"amazon.titan-embed-text-v2:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1679fa1-52cb-4470-8f09-539bc8ce0b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing query How is my transformer fleet - 2217, 1235, 1685 and 2484 doing? - Hybrid Search:\n",
      "Numerical Keywords: [TXID_2217, TXID_1235, TXID_1685, TXID_2484]; Text Keywords: []\n"
     ]
    }
   ],
   "source": [
    "search_result = test_queries(index_name, QUERIES['4'], opensearch_client, embedding_model, 'hybrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e40811-ff75-44aa-8264-8928eaa99cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4fb565b-7181-4dd7-a0d4-dfbaf2bfbfc8",
   "metadata": {},
   "source": [
    "# Call Titan LLM Model for contextual output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e9ca1cd-f6a0-465d-8c63-79f2a2c2a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, user_prompt, system_prompt):\n",
    "    input_prompt = f\"System: {system_prompt}\\n\\nHuman: {user_prompt}\\n\\nAI:\"\n",
    "    \n",
    "    response = model.invoke(\n",
    "        input=input_prompt\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "\n",
    "def clean_response(raw_response):\n",
    "    raw_text = raw_response.content\n",
    "    cleaned_response = raw_text.strip()\n",
    "    \n",
    "    return cleaned_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f937e46f-43fa-4ffc-861d-25f2a5bdf2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query  Which transformer is needing an immediate attention?\n",
      "\n",
      "Testing query Which transformer is needing an immediate attention? - Hybrid Search:\n",
      "Numerical Keywords: []; Text Keywords: [attention]\n",
      "Based on the available data, there are no transformers that require immediate attention. All transformers are operating within normal parameters, and there are no alerts or incidents reported. However, it is important to note that regular maintenance and monitoring are crucial to ensure the continued safe and efficient operation of these transformers.\n"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "\n",
    "query = QUERIES['1']\n",
    "print(f\"Running query  {query}\")\n",
    "search_result=test_queries(index_name, query, opensearch_client, embedding_model, 'hybrid')\n",
    "user_prompt = search_result\n",
    "system_prompt = \"\"\"You are a specialized assistant trained to provide information only related to power transformers. You have access to detailed operational, environmental, and performance data for each transformer. If a transformer ID is mentioned, you should provide accurate and factual information related only to that transformer and not generalize across other transformers. You are expected to avoid answering any queries outside the scope of power transformer maintenance, operation, and health.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Use only the information from the dataset, and avoid relying on external knowledge for answering questions.\n",
    "2. Always respond with precise data when the transformer ID is mentioned, only referring to the specified transformer.\n",
    "3. When multiple transformer IDs are mentioned, compare them side by side using parameters from the dataset (e.g., hydrogen level, temperature, performance metrics, etc.).\n",
    "4. Flag any transformer needing attention based on unusual parameter readings (e.g., high hydrogen, low operating time, specific alerts).\n",
    "5. Reject any queries outside the scope of transformer health, operation, or maintenance.\n",
    "6. Provide detailed responses.\n",
    "\n",
    "**DO NOT HALLUCINATE.**\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = generate_response(model, user_prompt, system_prompt)\n",
    "\n",
    "cleaned_response = clean_response(response)\n",
    "print(cleaned_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1943c7bc-7b93-452e-bdc8-6b13bef45fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which transformer is needing an immediate attention?\n",
      "Based on the available data, there are no transformers that require immediate attention. All transformers are operating within normal parameters, and there are no alerts or incidents reported. However, it is important to note that regular maintenance and monitoring are crucial to ensure the continued safe and efficient operation of these transformers.\n"
     ]
    }
   ],
   "source": [
    "print(query)\n",
    "print(cleaned_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a956befb-c765-43e2-8e53-967bc246e17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing query Which transformer is needing an immediate attention? - Hybrid Search:\n",
      "Must Keywords: []\n",
      "Should Keywords: ['transformer', 'attention', 'immediate attention']\n",
      "# Query: Which transformer is needing an immediate attention? (Hybrid search)\n",
      "--------------------------------\n",
      "# Hybrid search result 1 (relevant document chunk):\n",
      "Source: health_index_augdata.csv\n",
      "Content:\n",
      "'Hydrogen': 106\n",
      "'Oxigen': 581\n",
      "'Nitrogen': 75200\n",
      "'Methane': 47\n",
      "'CO': 760\n",
      "'CO2': 4070\n",
      "'Ethylene': 11\n",
      "'Ethane': 30\n",
      "'Acethylene': 0\n",
      "'DBDS': 183.0\n",
      "'Power factor': 0.16\n",
      "'Interfacial V': 43\n",
      "'Dielectric rigidity': 29\n",
      "'Water content': 5\n",
      "'Health index': 58.3\n",
      "'Life expectation': 6.1\n",
      "'CO_H2_ratio': 7.169811320754717\n",
      "'CH4_H2_ratio': 0.4433962264150943\n",
      "'C2H4_H2_ratio': 0.1037735849056603\n",
      "'C2H2_H2_ratio': 0.0\n",
      "'H2_N2_ratio': 0.0014095744680851\n",
      "'O2_N2_ratio': 0.0077260638297872\n",
      "'H2_CO2_ratio': 0.026044226044226\n",
      "'TransformerID': TxID_4748\n",
      "'InstallationDate': 2013-02-23\n",
      "'MaintenanceSchedule': 2022-10-02\n",
      "'ReplacementHistory': No major replacements\n",
      "'MaintenanceID': MNT-27287\n",
      "'MaintenanceType': Preventive Maintenance\n",
      "'MaintenanceDate': 2023-07-06\n",
      "'TransformerLoad': 190.39443892923836\n",
      "'Temperature': 36.04625172234671\n",
      "'Humidity': 65.30795669168775\n",
      "'Precipitation': 17.806366272672864\n",
      "'Alerts': None\n",
      "'IncidentType': Storm\n",
      "'IncidentDetails': Severe weather affecting transformer\n",
      "'OperationID': OP-2711\n",
      "'OperatingTime': 34.41280523261736\n",
      "'LoadCondition': Normal Load\n",
      "'PerformanceMetrics': Performance with a load of 190.39443892923833 KW and temperature 36.04625172234671°C. Operating conditions were impacted by Severe weather affecting transformer.\n",
      "--------------------------------\n",
      "# Hybrid search result 2 (relevant document chunk):\n",
      "Source: health_index_augdata.csv\n",
      "Content:\n",
      "'Hydrogen': 87\n",
      "'Oxigen': 362\n",
      "'Nitrogen': 76100\n",
      "'Methane': 47\n",
      "'CO': 560\n",
      "'CO2': 3920\n",
      "'Ethylene': 5\n",
      "'Ethane': 31\n",
      "'Acethylene': 0\n",
      "'DBDS': 184.0\n",
      "'Power factor': 0.23\n",
      "'Interfacial V': 43\n",
      "'Dielectric rigidity': 52\n",
      "'Water content': 4\n",
      "'Health index': 57.4\n",
      "'Life expectation': 17.5\n",
      "'CO_H2_ratio': 6.436781609195402\n",
      "'CH4_H2_ratio': 0.5402298850574713\n",
      "'C2H4_H2_ratio': 0.057471264367816\n",
      "'C2H2_H2_ratio': 0.0\n",
      "'H2_N2_ratio': 0.001143232588699\n",
      "'O2_N2_ratio': 0.0047568988173455\n",
      "'H2_CO2_ratio': 0.0221938775510204\n",
      "'TransformerID': TxID_4828\n",
      "'InstallationDate': 2003-04-18\n",
      "'MaintenanceSchedule': 2022-05-25\n",
      "'ReplacementHistory': No major replacements\n",
      "'MaintenanceID': MNT-41410\n",
      "'MaintenanceType': Preventive Maintenance\n",
      "'MaintenanceDate': 2022-11-03\n",
      "'TransformerLoad': 622.4876404378366\n",
      "'Temperature': 99.24713073488988\n",
      "'Humidity': 61.828999832586135\n",
      "'Precipitation': 32.77102728728869\n",
      "'Alerts': High Temperature Alert\n",
      "'IncidentType': Storm\n",
      "'IncidentDetails': Severe weather affecting transformer\n",
      "'OperationID': OP-8221\n",
      "'OperatingTime': 34.25405227311811\n",
      "'LoadCondition': Normal Load\n",
      "'PerformanceMetrics': Performance with a load of 622.4876404378366 KW and temperature 99.24713073488988°C. Operating conditions were impacted by Severe weather affecting transformer.\n",
      "--------------------------------\n",
      "\n",
      "Transformer ID: TxID_4828\n",
      "\n",
      "Health Index: 57.4\n",
      "\n",
      "Power Factor: 0.23\n",
      "\n",
      "Operating Time: 34.25 years\n",
      "\n",
      "Load Condition: Normal Load\n",
      "\n",
      "Performance Metrics: Performance with a load of 622.4876404378366 KW and temperature 99.24713073488988°C. Operating conditions were impacted by Severe weather affecting transformer.\n",
      "\n",
      "Alerts: High Temperature Alert\n",
      "\n",
      "Incident Type: Storm\n",
      "\n",
      "Incident Details: Severe weather affecting transformer\n",
      "\n",
      "Maintenance History: Preventive Maintenance on 2022-11-03\n",
      "\n",
      "Transformer ID: TxID_4748\n",
      "\n",
      "Health Index: 58.3\n",
      "\n",
      "Power Factor: 0.16\n",
      "\n",
      "Operating Time: 9.99 years\n",
      "\n",
      "Load Condition: Normal Load\n",
      "\n",
      "Performance Metrics: Performance with a load of 190.39443892923833 KW and temperature 36.04625172234671°C. Operating conditions were impacted by Severe weather affecting transformer.\n",
      "\n",
      "Alerts: None\n",
      "\n",
      "Incident Type: Storm\n",
      "\n",
      "Incident Details: Severe weather affecting transformer\n",
      "\n",
      "Maintenance History: Preventive Maintenance on 2023-07-06\n",
      "\n",
      "Transformer ID: TxID_4828 has a lower health index (57.4) compared to TxID_4748 (58.3), indicating a higher risk of failure. Additionally, TxID_4828 has a high temperature alert, which could indicate overheating and potential damage to the transformer. Preventive maintenance was performed on TxID_4828 on 2022-11-03, but further investigation and potential corrective actions may be necessary to address the high temperature issue. On the other hand, TxID_4748 has a lower power factor (0.16) compared to TxID_4828 (0.23), which could indicate inefficiencies in the transformer's operation. However, there are no alerts or incidents reported for TxID_4748, and preventive maintenance was performed on 2023-07-06. Overall, TxID_4828 appears to be in a more critical condition and may require immediate attention.\n"
     ]
    }
   ],
   "source": [
    "from requests_aws4auth import AWS4Auth\n",
    "import boto3\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from langchain_aws import ChatBedrock\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import time \n",
    "\n",
    "QUERIES = {\n",
    "    '1': 'Which transformer is needing an immediate attention?',\n",
    "    '2': 'For transformers 2217, 1235, 1685 and 2484 provide comparative details for transformer health based on Oil quality testing ( dielectric breakdown voltage, IFT, acidity, moisture content, furan analysis) , DGA ( duval, rogers ratio, key gas method), Power factor (IPF/IR), temperature monitoring (top oil temperature , hot spot temperature, cooling efficiency) , load/overload history ( loading prof, percentage overload), partial discharge , electrical testing ( FRA, WRM, Turns ratio, capacitance and dissipation factor) , TAIM, LEDT, dornenburgs method, bushing health (capacitance and power factor, DGA for bushings), THI (HI, risk of failure), LTC. Ensure you provide details on parameter, significance, calculation details, root cause analysis details, actions and measures that must be taken , advice to curb further damage for provided transformer details in a tabular format',\n",
    "    '3': 'what is the duval triangle 1,2,3 value for transformer 2484',\n",
    "    '4': 'How is my transformer fleet - 2217, 1235, 1685 and 2484 doing?'\n",
    "}\n",
    "INDEX_CONFIG ={'Hackathon_index': 'innovator_hack_index'}\n",
    "\n",
    "opensearch_host = 'iellhhrn6kean028im78.us-east-1.aoss.amazonaws.com'\n",
    "opensearch_port = 443\n",
    "opensearch_region = 'us-east-1'\n",
    "opensearch_service = 'aoss'\n",
    "index_name = INDEX_CONFIG['Hackathon_index']\n",
    "dimension = 1024\n",
    "\n",
    "# Initialize OpenSearch client\n",
    "def init_opensearch_client(host, port, region, service):\n",
    "    credentials = boto3.Session().get_credentials()\n",
    "    awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
    "    return OpenSearch(\n",
    "        hosts=[{'host': host, 'port': port}],\n",
    "        http_auth=awsauth,\n",
    "        use_ssl=True,\n",
    "        verify_certs=True,\n",
    "        connection_class=RequestsHttpConnection,\n",
    "        timeout=3000\n",
    "    )\n",
    "opensearch_client = init_opensearch_client(opensearch_host, opensearch_port, opensearch_region, opensearch_service)\n",
    "embedding_model = BedrockEmbeddings(client=boto3.client(\"bedrock-runtime\", region_name=opensearch_region), model_id=\"amazon.titan-embed-text-v2:0\")\n",
    "\n",
    "def load_model():\n",
    "    bedrock_runtime = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=\"us-east-1\",\n",
    "    )\n",
    "    # Updated model with more balanced temperature and top_p\n",
    "    model_id = \"amazon.titan-text-premier-v1:0\"\n",
    "    model_kwargs = {\n",
    "        \"temperature\": 0       \n",
    "    }\n",
    "    model = ChatBedrock(\n",
    "        client=bedrock_runtime,\n",
    "        model_id=model_id,\n",
    "        model_kwargs=model_kwargs,\n",
    "    ).with_retry()\n",
    "    return model\n",
    "\n",
    "def parse_keywords(content):\n",
    "    must_keywords = []\n",
    "    should_keywords = []\n",
    "\n",
    "    # Extract the Must Keywords line\n",
    "    must_line = re.search(r'Numerical Keywords: \\[(.*?)\\]', content)\n",
    "    if must_line:\n",
    "        must_keywords = [keyword.strip() for keyword in must_line.group(1).split(',')]\n",
    "\n",
    "    # Extract the Should Keywords line\n",
    "    should_line = re.search(r'Text Keywords: \\[(.*?)\\]', content)\n",
    "    if should_line:\n",
    "        should_keywords = [keyword.strip() for keyword in should_line.group(1).split(',')]\n",
    "\n",
    "    return must_keywords, should_keywords\n",
    "\n",
    "def extract_keywords(query):\n",
    "    # List of domain-specific keywords for transformer health and other common queries\n",
    "    health_keywords = [\n",
    "        \"oil quality\", \"dielectric breakdown voltage\", \"IFT\", \"acidity\", \"moisture content\", \n",
    "        \"furan analysis\", \"DGA\", \"duval\", \"rogers ratio\", \"key gas\", \"power factor\", \n",
    "        \"IPF\", \"IR\", \"temperature monitoring\", \"top oil temperature\", \"hot spot temperature\", \n",
    "        \"cooling efficiency\", \"load history\", \"overload history\", \"partial discharge\", \n",
    "        \"electrical testing\", \"FRA\", \"WRM\", \"turns ratio\", \"capacitance\", \n",
    "        \"dissipation factor\", \"TAIM\", \"LEDT\", \"dornenburg method\", \"bushing health\", \n",
    "        \"THI\", \"risk of failure\", \"LTC\", \"transformer\", \"attention\", \"failure\", \"immediate attention\"\n",
    "    ]\n",
    "    \n",
    "    # Extract transformer IDs (numerical keywords)\n",
    "    must_keywords = re.findall(r'\\b\\d+\\b', query)\n",
    "    for i, keyword in enumerate(must_keywords):\n",
    "        if not keyword.startswith('TXID_'):\n",
    "            must_keywords[i] = 'TXID_' + keyword\n",
    "\n",
    "    # Extract health-related keywords (text keywords)\n",
    "    should_keywords = []\n",
    "    for keyword in health_keywords:\n",
    "        if keyword.lower() in query.lower():\n",
    "            should_keywords.append(keyword)\n",
    "\n",
    "    return must_keywords, should_keywords\n",
    "\n",
    "def keyword_search(opensearch_client, index_name, query, k=2):\n",
    "    must_keywords, should_keywords = extract_keywords(query)\n",
    "    \n",
    "    # Debugging: Print the extracted keywords\n",
    "    print(\"Must Keywords:\", must_keywords)\n",
    "    print(\"Should Keywords:\", should_keywords)\n",
    "\n",
    "    if not must_keywords and not should_keywords:\n",
    "        # No keywords found, return early with empty result\n",
    "        print(\"No keywords found for the query.\")\n",
    "        return []\n",
    "\n",
    "    msearch_body = []\n",
    "    if must_keywords:\n",
    "        for keyword in must_keywords:\n",
    "            msearch_body.append({'index': index_name})\n",
    "            msearch_body.append({\n",
    "                'size': k, \n",
    "                'query': {\n",
    "                    'bool': {\n",
    "                        'must': [\n",
    "                            {\n",
    "                                'match_phrase': {\n",
    "                                    'content': keyword\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                        'should': [\n",
    "                            {\n",
    "                                'match': {\n",
    "                                    'content': should_keyword\n",
    "                                }\n",
    "                            } for should_keyword in should_keywords\n",
    "                        ],\n",
    "                        'minimum_should_match': 0 \n",
    "                    }\n",
    "                }\n",
    "            })\n",
    "\n",
    "    else:\n",
    "            for keyword in should_keywords:\n",
    "                msearch_body.append({'index': index_name})\n",
    "                msearch_body.append({\n",
    "                    'size': k, \n",
    "                    'query': {\n",
    "                        'bool': {\n",
    "                            'should': [\n",
    "                                {\n",
    "                                    'match_phrase': {\n",
    "                                        'content': keyword\n",
    "                                    }\n",
    "                                }\n",
    "                            ],\n",
    "                            'minimum_should_match': 0 \n",
    "                        }\n",
    "                    }\n",
    "                })\n",
    "\n",
    "    # Ensure msearch_body is not empty before making the search call\n",
    "    if not msearch_body:\n",
    "        print(\"No search body constructed, returning empty result.\")\n",
    "        return []\n",
    "\n",
    "    response = opensearch_client.msearch(body=msearch_body)\n",
    "\n",
    "    all_results = []\n",
    "    for res in response['responses']:\n",
    "        if 'hits' in res and 'hits' in res['hits']:\n",
    "            all_results.extend(res['hits']['hits'])  \n",
    "\n",
    "    return all_results\n",
    "\n",
    "def vector_search(opensearch_client, index_name, embedding_model, query, k=2, similarity_threshold=0.75):\n",
    "    # Get the query embedding from the embedding model\n",
    "    query_vector = embedding_model.embed_documents([query])[0]\n",
    "    \n",
    "    # Perform semantic search using vector similarity (k-nearest neighbors search)\n",
    "    response = opensearch_client.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            'size': k,\n",
    "            'query': {\n",
    "                'knn': {\n",
    "                    'embedding': {\n",
    "                        'vector': query_vector,\n",
    "                        'k': k\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Filter results based on similarity threshold\n",
    "    filtered_results = [\n",
    "        result for result in response['hits']['hits'] if result['_score'] >= similarity_threshold\n",
    "    ]\n",
    "    \n",
    "    return filtered_results\n",
    "\n",
    "def hybrid_search(opensearch_client, index_name, embedding_model, query, k=2):\n",
    "    # Perform keyword-based search\n",
    "    keyword_results = keyword_search(opensearch_client, index_name, query, k)\n",
    "    \n",
    "    # Perform semantic (vector) search with similarity filtering\n",
    "    vector_results = vector_search(opensearch_client, index_name, embedding_model, query, k, similarity_threshold=0.75)\n",
    "    \n",
    "    # Combine results from both keyword and semantic search\n",
    "    combined_results = keyword_results + vector_results\n",
    "    \n",
    "    # Sort the combined results by relevance (score)\n",
    "    combined_results = sorted(combined_results, key=lambda x: x['_score'], reverse=True)\n",
    "    \n",
    "    return combined_results\n",
    "\n",
    "def print_query_result(query, results, search_type):\n",
    "    search_results = \"\"\n",
    "\n",
    "    if not results:\n",
    "        search_results += f\"# Query: {query} ({search_type} search)\\n\"\n",
    "        search_results += \"--------------------------------\\n\"\n",
    "        search_results += \"No results found.\\n\"\n",
    "        search_results += \"--------------------------------\\n\"\n",
    "        print(search_results)\n",
    "        return search_results\n",
    "\n",
    "    # Combine all the results into a pandas DataFrame for better readability\n",
    "    df = pd.concat([pd.DataFrame([result['_source'] if isinstance(result, dict) else result]) for result in results], ignore_index=True)\n",
    "    \n",
    "    search_results += f\"# Query: {query} ({search_type} search)\\n\"\n",
    "    search_results += \"--------------------------------\\n\"\n",
    "    for i, result in enumerate(results):\n",
    "        metadata = result['_source'] if isinstance(result, dict) else result\n",
    "        search_results += f\"# {search_type} search result {i+1} (relevant document chunk):\\n\"\n",
    "        search_results += f\"Source: {metadata.get('source', 'Unknown')}\\n\"\n",
    "        search_results += \"Content:\\n\"\n",
    "        row_content = json.loads(metadata['content']) if 'content' in metadata else metadata\n",
    "        for key, value in row_content.items():\n",
    "            search_results += f\"'{key}': {value}\\n\"\n",
    "        search_results += \"--------------------------------\\n\"\n",
    "\n",
    "    print(search_results)\n",
    "    return search_results\n",
    "\n",
    "\n",
    "def format_output(query, results):\n",
    "    formatted_results = []\n",
    "    for result in results:\n",
    "        formatted_results.append(f\"<documents>\\n{result}\\n</documents>\")\n",
    "    return f\"<query> # Query: {query} </query>\\n\" + \"\\n--------------------------------\\n\".join(formatted_results)\n",
    "\n",
    "\n",
    "def test_queries(index_name, query, opensearch_client, embedding_model, search_type):\n",
    "    search_result = \"\"\n",
    "    if search_type == 'keyword':\n",
    "        print(f\"\\nTesting query {query} - Keyword Search:\")\n",
    "        results = keyword_search(opensearch_client, index_name, query)\n",
    "        search_result = print_query_result(query, results, \"Keyword\")\n",
    "    elif search_type == 'vector':\n",
    "        print(f\"\\nTesting query {query} - Vector Search:\")\n",
    "        results = vector_search(opensearch_client, index_name, embedding_model, query)\n",
    "        search_result = print_query_result(query, results, \"Vector\")\n",
    "    elif search_type == 'hybrid':\n",
    "        print(f\"\\nTesting query {query} - Hybrid Search:\")\n",
    "        results = hybrid_search(opensearch_client, index_name, embedding_model, query)\n",
    "        search_result = print_query_result(query, results, \"Hybrid\")\n",
    "    else:\n",
    "        print(f\"Unknown search type: {search_type}\")\n",
    "\n",
    "    formatted_output = format_output(query, [search_result])\n",
    "    return formatted_output\n",
    "\n",
    "# Run the query test with hybrid search\n",
    "search_result = test_queries(index_name, \"Which transformer is needing an immediate attention?\", opensearch_client, embedding_model, 'hybrid')\n",
    "\n",
    "# Example prompt formatting for the LLM\n",
    "with open(\"prompt_cot.txt\", 'r') as file:\n",
    "        system_prompt = file.read()\n",
    "\n",
    "def generate_response(model, user_prompt, system_prompt):\n",
    "    input_prompt = f\"\"\"\n",
    "    System: {system_prompt}\n",
    "    \n",
    "    Human: Based on the search results from both keyword and semantic search, here is the relevant information: {user_prompt}.\n",
    "    \n",
    "    AI: Please provide a summary of the transformer health and status, including any critical issues or necessary actions.\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.invoke(\n",
    "        input=input_prompt\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "def clean_response(raw_response):\n",
    "    # Assuming the response content is stored in a `content` attribute\n",
    "    raw_text = raw_response.content\n",
    "    # Strip any unnecessary whitespace from the beginning and end of the response\n",
    "    cleaned_response = raw_text.strip()\n",
    "    \n",
    "    return cleaned_response\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "#query = QUERIES['1']\n",
    "\n",
    "query = \"Which transformer is needing an immediate attention?\"\n",
    "\n",
    "# Validate search results\n",
    "if not search_result:\n",
    "    print(\"No valid results found from the knowledge base.\")\n",
    "else:\n",
    "    user_prompt = search_result\n",
    "    response = generate_response(model, user_prompt, system_prompt)\n",
    "    cleaned_response = clean_response(response)\n",
    "    print(cleaned_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707233d0-a929-41bb-92b7-bc3ee3e4109b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
