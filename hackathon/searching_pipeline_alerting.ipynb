{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7223cf5f-eccc-4b89-b416-bdb0fdfa7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_aws4auth import AWS4Auth\n",
    "import boto3\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "#from langchain_community.embeddings import BedrockEmbeddings\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from langchain_aws import ChatBedrock\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8ca18b7-f59f-4b2e-8c50-f0f28f30f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain-aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0af1d58-bf92-46ba-8050-4ebeb210bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERIES = {\n",
    "    '1': 'provide comparative analysis of transformers - TXID_2217, TXID_1235, TXID_1685 and TXID_2484 based on their parameters',\n",
    "    '2': 'For transformers 2217, 1235, 1685 and 2484 provide comparative details for transformer health based on Oil quality testing ( dielectric breakdown voltage, IFT, acidity, moisture content, furan analysis) , DGA ( duval, rogers ratio, key gas method), Power factor (IPF/IR), temperature monitoring (top oil temperature , hot spot temperature, cooling efficiency) , load/overload history ( loading prof, percentage overload), partial discharge , electrical testing ( FRA, WRM, Turns ratio, capacitance and dissipation factor) , TAIM, LEDT, dornenburgs method, bushing health (capacitance and power factor, DGA for bushings), THI (HI, risk of failure), LTC. Ensure you provide details on parameter, significance, calculation details, root cause analysis details, actions and measures that must be taken , advice to curb further damage for provided transformer details in a tabular format',\n",
    "    '3': 'what is the duval triangle 1,2,3 value for transformer 2484',\n",
    "    '4': 'How is my transformer fleet - 2217, 1235, 1685 and 2484 doing?',\n",
    "    '5': 'Which are my high-risk transformers and how does one mitigate the risk?'\n",
    "}\n",
    "INDEX_CONFIG ={'Hackathon_index': 'testing_index2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "840f31c0-c5ed-449a-ae51-d3ff4b4c01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_aws import ChatBedrock\n",
    "import re\n",
    "\n",
    "def load_model():\n",
    "    # bedrock client\n",
    "    bedrock_runtime = boto3.client(\n",
    "        service_name=\"bedrock-runtime\",\n",
    "        region_name=\"us-east-1\",\n",
    "    )\n",
    "    # Update to use amazon.titan-text-premier-v1:0\n",
    "    model_id = \"amazon.titan-text-premier-v1:0\"\n",
    "    model_kwargs = {\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "    # Bedrock chat model\n",
    "    model = ChatBedrock(\n",
    "        client=bedrock_runtime,\n",
    "        model_id=model_id,\n",
    "        model_kwargs=model_kwargs,\n",
    "    ).with_retry()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767bcf6c-f3e5-4fb3-bb3c-4404cdabcc61",
   "metadata": {},
   "source": [
    "# Query Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "56776e96-8c68-4f6d-b104-a453af0f0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_router(query):\n",
    "    prompt =  f\"\"\"There are the following types of user queries: alert, trasnformer.\n",
    "                Use the following examples for reference:\n",
    "                'provide comparative analysis of transformers - 2217, 1235, 1685 and 2484 based on their parameters' -> transformer\n",
    "                'which transformer is needing immediate attention ?' -> alert\n",
    "                'which transformer needs inspection currently and for what ? ignore missing data' -> alert\n",
    "                'When will a transformer fail? which one first' -> alert\n",
    "                Classify the following request: {query}\"\"\"\n",
    "    \n",
    "    model = load_model()\n",
    "    response = model.invoke(prompt)\n",
    "    content = response.content\n",
    "    \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "11d09612-5cc6-478c-bcf5-376b4594cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_router('what is the duval triangle 1,2,3 value for transformer 2484')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eeadc7-abbb-4815-b533-912413491d75",
   "metadata": {},
   "source": [
    "# Keyword Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe1a942a-b43d-48d9-a05e-2d80463c30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_keywords(content):\n",
    "    must_keywords = []\n",
    "    should_keywords = []\n",
    "\n",
    "    # Extract the Must Keywords line\n",
    "    must_line = re.search(r'Numerical Keywords: \\[(.*?)\\]', content)\n",
    "    if must_line:\n",
    "        must_keywords = [keyword.strip() for keyword in must_line.group(1).split(',')]\n",
    "\n",
    "    # Extract the Should Keywords line\n",
    "    should_line = re.search(r'Text Keywords: \\[(.*?)\\]', content)\n",
    "    if should_line:\n",
    "        should_keywords = [keyword.strip() for keyword in should_line.group(1).split(',')]\n",
    "\n",
    "    return must_keywords, should_keywords\n",
    "\n",
    "def extract_keywords(query):\n",
    "    prompt = f\"\"\"\n",
    "    Extract the keywords from the following query: \"{query}\"\n",
    "    Keywords should include specific identifiers like transformer numbers, names, or other entities relevant to the query.\n",
    "    Transformer should never be a keyword.\n",
    "    If the keyword is clearly a transformer ID and it doesn't start with 'TXID_', add this to its prefix\n",
    "    The output should have format of: Numerical Keywords: [...]; Text Keywords: [...]\n",
    "    \n",
    "    <example>\n",
    "    Input: provide comparative analysis of transformers - 2217, 1235, 1685 and 2484 based on their parameters?\n",
    "    Output: Numerical Keyword: [TXID_2217, TXID_1235, TXID_1685, TXID_2484]; Text Keyword: …\n",
    "    \n",
    "    Input: what is the duval triangle 1,2,3 value for transformer 2484\n",
    "    Output: Numerical Keyword: [TXID_2484]; Text Keyword: [duval triangle]\n",
    "    \"\"\"\n",
    "    \n",
    "    model = load_model()\n",
    "    response = model.invoke(prompt)\n",
    "    \n",
    "    content = response.content\n",
    "    print(content)\n",
    "    \n",
    "    return parse_keywords(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627bf95-47fb-4590-b80a-7c84462193fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b81a62d4-309e-48f4-a0f8-920999688068",
   "metadata": {},
   "source": [
    "# Searching Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63f92948-1044-4bc4-a486-adccd9e35284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search(opensearch_client, index_name, query, k=2):\n",
    "    must_keywords, should_keywords = extract_keywords(query)\n",
    "\n",
    "    msearch_body = []\n",
    "    if must_keywords:\n",
    "        for keyword in must_keywords:\n",
    "            msearch_body.append({'index': index_name})\n",
    "            \n",
    "            msearch_body.append({\n",
    "                'size': k, \n",
    "                'query': {\n",
    "                    'bool': {\n",
    "                        'must': [\n",
    "                            {\n",
    "                                'match_phrase': {\n",
    "                                    'content': keyword\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                        'should': [\n",
    "                            {\n",
    "                                'match': {\n",
    "                                    'content': should_keyword\n",
    "                                }\n",
    "                            } for should_keyword in should_keywords\n",
    "                        ],\n",
    "                        'minimum_should_match': 0 \n",
    "                    }\n",
    "                }\n",
    "            })\n",
    "\n",
    "    response = opensearch_client.msearch(body=msearch_body)\n",
    "\n",
    "    all_results = []\n",
    "    for res in response['responses']:\n",
    "        if 'hits' in res and 'hits' in res['hits']:\n",
    "            all_results.extend(res['hits']['hits'])  \n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "\n",
    "def vector_search(opensearch_client, index_name, embedding_model, query, k=2):\n",
    "    query_vector = embedding_model.embed_documents([query])[0]\n",
    "    response = opensearch_client.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            'size': k,\n",
    "            'query': {\n",
    "                'knn': {\n",
    "                    'embedding': {\n",
    "                        'vector': query_vector,\n",
    "                        'k': k\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return response['hits']['hits']\n",
    "\n",
    "def alert_search(transformer_data, fault_ranges):\n",
    "    high_risk_transformers = {}\n",
    "\n",
    "    for transformer_id, data in transformer_data.items():\n",
    "        alerts = []\n",
    "        for param, value in data.items():\n",
    "            if param in fault_ranges:\n",
    "                ranges = fault_ranges[param]\n",
    "                if value > ranges['High']:\n",
    "                    alerts.append(f\"{param} is in the high-risk range: {value}.\")\n",
    "        \n",
    "        if alerts:\n",
    "            high_risk_transformers[transformer_id] = {\n",
    "                'alerts': alerts,\n",
    "                'mitigation': suggest_mitigation(alerts)\n",
    "            }\n",
    "\n",
    "\n",
    "    top_5_transformers = dict(list(high_risk_transformers.items())[:5])\n",
    "    \n",
    "    return top_5_transformers\n",
    "\n",
    "\n",
    "def print_query_result(query, results):\n",
    "    search_results = \"\"\n",
    "    \n",
    "    if not results:\n",
    "        search_results += f\"# Query: {query} (search)\"\n",
    "        search_results += \"--------------------------------\"\n",
    "        search_results += \"No results found.\"\n",
    "        search_results += \"--------------------------------\"\n",
    "        print(search_results)\n",
    "        return search_results\n",
    "\n",
    "    df = pd.concat([pd.DataFrame([result['_source'] if isinstance(result, dict) else result]) for result in results], ignore_index=True)\n",
    "    search_results += f\"# Query: {query} (search)\"\n",
    "    search_results += \"--------------------------------\"\n",
    "    for i, result in enumerate(results):\n",
    "        # print(result)\n",
    "        metadata = result['_source'] if isinstance(result, dict) else result\n",
    "        search_results += f\"# Search result {i+1} (relevant document chunk):\"\n",
    "        search_results += f\"Source: {metadata['source']}\"\n",
    "        search_results += \"Content:\"\n",
    "        row_content = json.loads(metadata['content'])\n",
    "        for key, value in row_content.items():\n",
    "            search_results += f\"'{key}': {value}\"\n",
    "        search_results +=  \"--------------------------------\"\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9438487d-087e-4333-95e7-9134a74bbb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing query Which are my high-risk transformers and how does one mitigate the risk? - Hybrid Search:\n",
      "Numerical Keywords: []; Text Keywords: [high-risk, mitigate, risk]\n",
      "<query> # Query: Which are my high-risk transformers and how does one mitigate the risk? </query>\n",
      "<documents>\n",
      "# Query: Which are my high-risk transformers and how does one mitigate the risk? (search)--------------------------------# Search result 1 (relevant document chunk):Source: health_index_augdata.csvContent:'Hydrogen': 4'Oxigen': 13600'Nitrogen': 37500'Methane': 3'CO': 443'CO2': 5890'Ethylene': 0'Ethane': 7'Acethylene': 0'DBDS': 0.0'Power factor': 1.0'Interfacial V': 34'Dielectric rigidity': 55'Water content': 77'Health index': 38.3'Life expectation': 32.0'CO_H2_ratio': 110.75'CH4_H2_ratio': 0.75'C2H4_H2_ratio': 0.0'C2H2_H2_ratio': 0.0'H2_N2_ratio': 0.0001066666666666'O2_N2_ratio': 0.3626666666666667'H2_CO2_ratio': 0.0006791171477079'TransformerID': TxID_5785'InstallationDate': 2002-07-05'MaintenanceSchedule': 2023-12-27'ReplacementHistory': No major replacements'MaintenanceID': MNT-16898'MaintenanceType': Preventive Maintenance'MaintenanceDate': 2023-12-29'TransformerLoad': 1503.3784178385124'Temperature': 33.4678351610073'Humidity': 70.08342275563929'Precipitation': 19.70210310402661'Alerts': None'IncidentType': Storm'IncidentDetails': Severe weather affecting transformer'OperationID': OP-5843'OperatingTime': 30.1255379145577'LoadCondition': High Load'PerformanceMetrics': Performance with a load of 1503.3784178385124 KW and temperature 33.4678351610073°C. Operating conditions were impacted by Severe weather affecting transformer.--------------------------------# Search result 2 (relevant document chunk):Source: health_index_augdata.csvContent:'Hydrogen': 11'Oxigen': 265'Nitrogen': 50800'Methane': 2'CO': 54'CO2': 1050'Ethylene': 0'Ethane': 63'Acethylene': 0'DBDS': 0.0'Power factor': 1.0'Interfacial V': 30'Dielectric rigidity': 50'Water content': 16'Health index': 13.4'Life expectation': 51.0'CO_H2_ratio': 4.909090909090909'CH4_H2_ratio': 0.1818181818181818'C2H4_H2_ratio': 0.0'C2H2_H2_ratio': 0.0'H2_N2_ratio': 0.0002165354330708'O2_N2_ratio': 0.0052165354330708'H2_CO2_ratio': 0.0104761904761904'TransformerID': TxID_2063'InstallationDate': 2013-03-01'MaintenanceSchedule': 2020-03-29'ReplacementHistory': No major replacements'MaintenanceID': MNT-48202'MaintenanceType': Preventive Maintenance'MaintenanceDate': 2020-11-27'TransformerLoad': 1830.4796193515715'Temperature': 56.73517463179991'Humidity': 32.353271123024776'Precipitation': 24.213021386753624'Alerts': None'IncidentType': Storm'IncidentDetails': Severe weather affecting transformer'OperationID': OP-3340'OperatingTime': 19.409260473437964'LoadCondition': High Load'PerformanceMetrics': Performance with a load of 1830.4796193515713 KW and temperature 56.73517463179991°C. Operating conditions were impacted by Severe weather affecting transformer.--------------------------------\n",
      "</documents>\n"
     ]
    }
   ],
   "source": [
    "search_result = test_queries(index_name, QUERIES['5'], opensearch_client, embedding_model, 'transformer')\n",
    "print(search_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb675ae0-834c-49e9-bfaf-54fe2bb1b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_queries(index_name, query, opensearch_client, embedding_model, search_type):\n",
    "\n",
    "    if search_type == 'transformer': #Hybrid\n",
    "        print(f\"\\nTesting query {query} - Hybrid Search:\")\n",
    "        results = keyword_search(opensearch_client, index_name, query) + vector_search(opensearch_client, index_name, embedding_model, query)\n",
    "    elif search_type == 'alert':\n",
    "        print('Hit alerting logic')\n",
    "        results = alert_search(transformer_data, fault_ranges)\n",
    "    search_result = print_query_result(query, results)\n",
    "\n",
    "\n",
    "    formatted_output = format_output(query, [search_result])\n",
    "    # print(formatted_output)\n",
    "    return formatted_output\n",
    "\n",
    "def format_output(query, results):\n",
    "    formatted_results = []\n",
    "    for result in results:\n",
    "        formatted_results.append(f\"<documents>\\n{result}\\n</documents>\")\n",
    "    return f\"<query> # Query: {query} </query>\\n\" + \"\\n--------------------------------\\n\".join(formatted_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6aeba31f-1591-47b0-96a2-89341ec344cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenSearch client\n",
    "def init_opensearch_client(host, port, region, service):\n",
    "    credentials = boto3.Session().get_credentials()\n",
    "    awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
    "    return OpenSearch(\n",
    "        hosts=[{'host': host, 'port': port}],\n",
    "        http_auth=awsauth,\n",
    "        use_ssl=True,\n",
    "        verify_certs=True,\n",
    "        connection_class=RequestsHttpConnection,\n",
    "        timeout=3000\n",
    "    )\n",
    "\n",
    "\n",
    "opensearch_host = 'iellhhrn6kean028im78.us-east-1.aoss.amazonaws.com'\n",
    "opensearch_port = 443\n",
    "opensearch_region = 'us-east-1'\n",
    "opensearch_service = 'aoss'\n",
    "index_name = INDEX_CONFIG['Hackathon_index']\n",
    "dimension = 1024\n",
    "\n",
    "opensearch_client = init_opensearch_client(opensearch_host, opensearch_port, opensearch_region, opensearch_service)\n",
    "embedding_model = BedrockEmbeddings(client=boto3.client(\"bedrock-runtime\", region_name=opensearch_region), model_id=\"amazon.titan-embed-text-v2:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1679fa1-52cb-4470-8f09-539bc8ce0b07",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'results' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m search_result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQUERIES\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopensearch_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhybrid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[73], line 9\u001b[0m, in \u001b[0;36mtest_queries\u001b[0;34m(index_name, query, opensearch_client, embedding_model, search_type)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHit alerting logic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     results \u001b[38;5;241m=\u001b[39m alert_search(transformer_data, fault_ranges)\n\u001b[0;32m----> 9\u001b[0m search_result \u001b[38;5;241m=\u001b[39m print_query_result(query, \u001b[43mresults\u001b[49m)\n\u001b[1;32m     12\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_output(query, [search_result])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# print(formatted_output)\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'results' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "search_result = test_queries(index_name, QUERIES['4'], opensearch_client, embedding_model, 'hybrid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28e40811-ff75-44aa-8264-8928eaa99cc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#alert_search(opensearch_client, 'testing_index2', embedding_model, 'check insulation power factor', k=5, alert_keywords=['insulation', 'resistance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb565b-7181-4dd7-a0d4-dfbaf2bfbfc8",
   "metadata": {},
   "source": [
    "# Call Titan LLM Model for contextual output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ca1cd-f6a0-465d-8c63-79f2a2c2a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, user_prompt, system_prompt):\n",
    "    input_prompt = f\"System: {system_prompt}\\n\\nHuman: {user_prompt}\\n\\nAI:\"\n",
    "    \n",
    "    response = model.invoke(\n",
    "        input=input_prompt\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "\n",
    "def clean_response(raw_response):\n",
    "    raw_text = raw_response.content\n",
    "    cleaned_response = raw_text.strip()\n",
    "    \n",
    "    return cleaned_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937e46f-43fa-4ffc-861d-25f2a5bdf2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()\n",
    "\n",
    "query = QUERIES['5']\n",
    "print(f\"Running query  {query}\")\n",
    "\n",
    "search_type=query_router(query)\n",
    "\n",
    "search_result=test_queries(index_name, query, opensearch_client, embedding_model, search_type)\n",
    "user_prompt = search_result\n",
    "system_prompt = \"\"\"You are a specialized assistant trained to provide information only related to power transformers. You have access to detailed operational, environmental, and performance data for each transformer. If a transformer ID is mentioned, you should provide accurate and factual information related only to that transformer and not generalize across other transformers. You are expected to avoid answering any queries outside the scope of power transformer maintenance, operation, and health.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Use only the information from the dataset, and avoid relying on external knowledge for answering questions.\n",
    "2. Always respond with precise data when the transformer ID is mentioned, only referring to the specified transformer.\n",
    "3. When multiple transformer IDs are mentioned, compare them side by side using parameters from the dataset (e.g., hydrogen level, temperature, performance metrics, etc.).\n",
    "4. Flag any transformer needing attention based on unusual parameter readings (e.g., high hydrogen, low operating time, specific alerts).\n",
    "5. Reject any queries outside the scope of transformer health, operation, or maintenance.\n",
    "\n",
    "Few-Shot Examples:\n",
    "\n",
    "Few-Shot Example 1: Comparative Analysis of Transformers\n",
    "User Query: \"Provide a comparative analysis of transformers 2217, 1235, 1685, and 2484 based on their parameters.\"\n",
    "\n",
    "Model Response:\n",
    "\n",
    "Parameter: Installation Date:\n",
    "\n",
    "Transformer 2217: 12/4/2001\n",
    "Transformer 1235: 12/25/2006\n",
    "Transformer 1685: 6/9/2013\n",
    "Transformer 2484: 8/20/2010\n",
    "Parameter: Load Condition:\n",
    "\n",
    "Transformer 2217: Normal Load\n",
    "Transformer 1235: High Load\n",
    "Transformer 1685: Normal Load\n",
    "Transformer 2484: High Load\n",
    "Parameter: Operating Temperature (°C):\n",
    "\n",
    "Transformer 2217: 69.74°C\n",
    "Transformer 1235: 86.65°C\n",
    "Transformer 1685: 35.78°C\n",
    "Transformer 2484: 58.46°C\n",
    "Parameter: Health Index:\n",
    "\n",
    "Transformer 2217: 13.4\n",
    "Transformer 1235: 13.4\n",
    "Transformer 1685: 13.4\n",
    "Transformer 2484: 13.5\n",
    "Parameter: Expected Remaining Life (Years):\n",
    "\n",
    "Transformer 2217: 51 years\n",
    "Transformer 1235: 51 years\n",
    "Transformer 1685: 51 years\n",
    "Transformer 2484: 51 years\n",
    "Parameter: Dissolved Gases (Hydrogen, Oxygen, Nitrogen):\n",
    "\n",
    "Transformer 2217: H₂ - 5, O₂ - 3860, N₂ - 29300\n",
    "Transformer 1235: H₂ - 3, O₂ - 13900, N₂ - 3600\n",
    "Transformer 1685: H₂ - 35, O₂ - 232, N₂ - 61400\n",
    "Transformer 2484: H₂ - 52, O₂ - 1710, N₂ - 56300\n",
    "This analysis is strictly based on the provided dataset and only includes the mentioned transformers.\n",
    "\n",
    "Few-Shot Example 2: Transformer Needing Immediate Attention\n",
    "User Query: \"Which transformer is needing immediate attention?\"\n",
    "\n",
    "Model Response: The transformer requiring immediate attention is TxID 1235 due to the following issues:\n",
    "\n",
    "High Moisture Content: 35 mg/L, significantly above acceptable limits. High moisture can degrade insulating properties.\n",
    "Elevated Temperatures: Top oil temperature is 86.65°C, and the hot spot temperature is 92°C, which can accelerate insulation wear.\n",
    "Dissolved Gas Analysis (DGA): Duval ratio of 3.0 indicates potential thermal issues. Rogers ratio of 0.33 also suggests insulation or overheating concerns.\n",
    "High Load Condition: The transformer is operating at 1769.88 KW, 25% overload.\n",
    "Immediate inspection and measures should be taken to prevent failure.\n",
    "\n",
    "Few-Shot Example 3: Standard Moisture Content for Oil Quality Testing\n",
    "User Query: \"What's the standard moisture content for oil quality testing?\"\n",
    "\n",
    "Model Response: Standard moisture content ranges for transformer oil quality are as follows:\n",
    "\n",
    "New or Dry Oil: Less than 10 mg/L, indicating minimal water contamination.\n",
    "In-Service Oil (Good Condition): Less than 20 mg/L, showing the oil is in good condition with low risk of insulation degradation.\n",
    "Moderate Condition: 20-30 mg/L, acceptable but requires monitoring and possibly oil drying.\n",
    "Critical Condition: Greater than 30 mg/L, indicating high moisture levels that could lead to insulation breakdown and increased failure risk.\n",
    "Few-Shot Example 4: Duval Triangle Values for Transformer 2484\n",
    "User Query: \"What is the Duval Triangle 123 value for transformer 2484?\"\n",
    "\n",
    "Model Response: For Transformer TxID_2484, the Duval Triangle gas concentration values and percentages are as follows:\n",
    "\n",
    "Duval Triangle 1: CH₄: 3, C₂H₄: 5, C₂H₂: 0\n",
    "CH₄: 37.5%, C₂H₄: 62.5%, C₂H₂: 0%\n",
    "Duval Triangle 2: H₂: 52, CH₄: 3, C₂H₂: 0\n",
    "H₂: 94.55%, CH₄: 5.45%, C₂H₂: 0%\n",
    "Duval Triangle 3: CH₄: 3, C₂H₄: 5, C₂H₆: 82\n",
    "CH₄: 3.23%, C₂H₄: 5.38%, C₂H₆: 91.39%\n",
    "\n",
    "**DO NOT HALLUCINATE.**\"\"\"\n",
    "response = generate_response(model, user_prompt, system_prompt)\n",
    "\n",
    "cleaned_response = clean_response(response)\n",
    "print(cleaned_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943c7bc-7b93-452e-bdc8-6b13bef45fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956befb-c765-43e2-8e53-967bc246e17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
